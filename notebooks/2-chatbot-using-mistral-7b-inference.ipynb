{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10442878,"sourceType":"datasetVersion","datasetId":6463705}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installing Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install accelerate peft bitsandbytes git+https://github.com/huggingface/transformers trl py7zr auto-gptq optimum -q\n!pip install unsloth -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:35:58.106196Z","iopub.execute_input":"2025-01-11T12:35:58.106570Z","iopub.status.idle":"2025-01-11T12:39:57.484454Z","shell.execute_reply.started":"2025-01-11T12:35:58.106539Z","shell.execute_reply":"2025-01-11T12:39:57.483185Z"}},"outputs":[{"name":"stdout","text":"  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.4/293.4 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.1/424.1 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.7/450.7 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.0/139.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.8/113.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.17 requires torch<2.5,>=1.10, but you have torch 2.5.1 which is incompatible.\ntorchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 2.5.1 which is incompatible.\ntorchvision 0.19.1+cu121 requires torch==2.4.1, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from peft import AutoPeftModelForCausalLM\nfrom transformers import GenerationConfig, AutoTokenizer, AutoModelForCausalLM, AutoTokenizer, GPTQConfig, TrainingArguments, TrainingArguments, DataCollatorForSeq2Seq\nimport torch\nimport time\n\nst_time = time.time()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:51:06.575111Z","iopub.execute_input":"2025-01-11T12:51:06.575467Z","iopub.status.idle":"2025-01-11T12:51:06.579960Z","shell.execute_reply.started":"2025-01-11T12:51:06.575439Z","shell.execute_reply":"2025-01-11T12:51:06.579127Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# Setting up tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"TheBloke/Mistral-7B-Instruct-v0.1-GPTQ\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:39:57.486247Z","iopub.execute_input":"2025-01-11T12:39:57.486657Z","iopub.status.idle":"2025-01-11T12:40:15.255733Z","shell.execute_reply.started":"2025-01-11T12:39:57.486615Z","shell.execute_reply":"2025-01-11T12:40:15.254916Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4662d381078949e891abf8d87d3fd140"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f87fbec132654e86b926235319b03ea4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71ddfc3d3a5544298e07b69bbab23b5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3643c8638a4041d1b72ebfe84f16dd58"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Setting up the model","metadata":{}},{"cell_type":"code","source":"model = AutoPeftModelForCausalLM.from_pretrained(\n    \"/kaggle/input/mistral-finetuned-checkpoints/mistral_finetuned_checkpoints\",\n    low_cpu_mem_usage=True,\n    return_dict=True,\n    torch_dtype=torch.float16,\n    device_map=\"cuda\")\n\nquantization_config_loading = GPTQConfig(bits=4, disable_exllama=True, tokenizer=tokenizer)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n                            \"/kaggle/input/mistral-finetuned-checkpoints/mistral_finetuned_checkpoints\",\n                            quantization_config=quantization_config_loading,\n                            device_map=\"auto\"\n                        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:42:04.963303Z","iopub.execute_input":"2025-01-11T12:42:04.963707Z","iopub.status.idle":"2025-01-11T12:42:33.787402Z","shell.execute_reply.started":"2025-01-11T12:42:04.963677Z","shell.execute_reply":"2025-01-11T12:42:33.786339Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/963 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5374a0865c78437eb2df43f151dfa4e3"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/auto_gptq/nn_modules/triton_utils/kernels.py:411: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  def forward(ctx, input, qweight, scales, qzeros, g_idx, bits, maxq):\n/usr/local/lib/python3.10/dist-packages/auto_gptq/nn_modules/triton_utils/kernels.py:419: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n  def backward(ctx, grad_output):\n/usr/local/lib/python3.10/dist-packages/auto_gptq/nn_modules/triton_utils/kernels.py:461: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  @custom_fwd(cast_inputs=torch.float16)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/4.16G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a820938751b4b2eb60f194d3c357570"}},"metadata":{}},{"name":"stderr","text":"`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\nSome weights of the model checkpoint at TheBloke/Mistral-7B-Instruct-v0.1-GPTQ were not used when initializing MistralForCausalLM: {'model.layers.18.mlp.down_proj.bias', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.14.mlp.up_proj.bias', 'model.layers.24.mlp.gate_proj.bias', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.31.mlp.down_proj.bias', 'model.layers.19.mlp.gate_proj.bias', 'model.layers.5.mlp.down_proj.bias', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.23.self_attn.o_proj.bias', 'model.layers.24.mlp.down_proj.bias', 'model.layers.11.mlp.down_proj.bias', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.12.mlp.gate_proj.bias', 'model.layers.7.self_attn.o_proj.bias', 'model.layers.22.self_attn.o_proj.bias', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.2.mlp.up_proj.bias', 'model.layers.7.mlp.up_proj.bias', 'model.layers.14.self_attn.o_proj.bias', 'model.layers.19.mlp.up_proj.bias', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.22.mlp.up_proj.bias', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.17.mlp.up_proj.bias', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.29.self_attn.o_proj.bias', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.30.self_attn.o_proj.bias', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.16.mlp.up_proj.bias', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.10.mlp.gate_proj.bias', 'model.layers.14.mlp.down_proj.bias', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.15.mlp.down_proj.bias', 'model.layers.18.mlp.gate_proj.bias', 'model.layers.16.self_attn.o_proj.bias', 'model.layers.28.mlp.gate_proj.bias', 'model.layers.12.self_attn.o_proj.bias', 'model.layers.27.mlp.gate_proj.bias', 'model.layers.4.mlp.up_proj.bias', 'model.layers.18.mlp.up_proj.bias', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.0.mlp.down_proj.bias', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.31.mlp.up_proj.bias', 'model.layers.16.mlp.gate_proj.bias', 'model.layers.23.mlp.gate_proj.bias', 'model.layers.21.mlp.gate_proj.bias', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.0.mlp.up_proj.bias', 'model.layers.10.self_attn.o_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.30.mlp.gate_proj.bias', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.26.mlp.down_proj.bias', 'model.layers.31.mlp.gate_proj.bias', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.28.self_attn.o_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.13.mlp.up_proj.bias', 'model.layers.10.mlp.down_proj.bias', 'model.layers.25.mlp.up_proj.bias', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.30.mlp.down_proj.bias', 'model.layers.27.mlp.down_proj.bias', 'model.layers.1.mlp.gate_proj.bias', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.13.mlp.gate_proj.bias', 'model.layers.3.mlp.gate_proj.bias', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.2.mlp.down_proj.bias', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.4.mlp.gate_proj.bias', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.19.mlp.down_proj.bias', 'model.layers.28.mlp.up_proj.bias', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.20.mlp.up_proj.bias', 'model.layers.23.mlp.up_proj.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.3.mlp.up_proj.bias', 'model.layers.9.self_attn.o_proj.bias', 'model.layers.8.mlp.gate_proj.bias', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.15.mlp.up_proj.bias', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.1.mlp.up_proj.bias', 'model.layers.16.mlp.down_proj.bias', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.8.mlp.down_proj.bias', 'model.layers.4.self_attn.o_proj.bias', 'model.layers.11.mlp.gate_proj.bias', 'model.layers.14.mlp.gate_proj.bias', 'model.layers.17.mlp.gate_proj.bias', 'model.layers.24.mlp.up_proj.bias', 'model.layers.19.self_attn.o_proj.bias', 'model.layers.25.mlp.gate_proj.bias', 'model.layers.5.self_attn.o_proj.bias', 'model.layers.29.mlp.gate_proj.bias', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.26.mlp.up_proj.bias', 'model.layers.9.mlp.gate_proj.bias', 'model.layers.23.mlp.down_proj.bias', 'model.layers.3.mlp.down_proj.bias', 'model.layers.20.mlp.gate_proj.bias', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.1.mlp.down_proj.bias', 'model.layers.6.mlp.up_proj.bias', 'model.layers.10.mlp.up_proj.bias', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.28.mlp.down_proj.bias', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.20.self_attn.o_proj.bias', 'model.layers.3.self_attn.o_proj.bias', 'model.layers.4.mlp.down_proj.bias', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.0.mlp.gate_proj.bias', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.22.mlp.gate_proj.bias', 'model.layers.26.self_attn.o_proj.bias', 'model.layers.2.mlp.gate_proj.bias', 'model.layers.11.mlp.up_proj.bias', 'model.layers.25.self_attn.o_proj.bias', 'model.layers.31.self_attn.o_proj.bias', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.29.mlp.down_proj.bias', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.0.self_attn.o_proj.bias', 'model.layers.17.self_attn.o_proj.bias', 'model.layers.1.self_attn.o_proj.bias', 'model.layers.21.mlp.up_proj.bias', 'model.layers.22.mlp.down_proj.bias', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.5.mlp.gate_proj.bias', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.7.mlp.down_proj.bias', 'model.layers.20.mlp.down_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.13.mlp.down_proj.bias', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.27.mlp.up_proj.bias', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.9.mlp.down_proj.bias', 'model.layers.29.mlp.up_proj.bias', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.21.mlp.down_proj.bias', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.17.mlp.down_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.6.self_attn.o_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.13.self_attn.o_proj.bias', 'model.layers.5.mlp.up_proj.bias', 'model.layers.26.mlp.gate_proj.bias', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.12.mlp.up_proj.bias', 'model.layers.24.self_attn.o_proj.bias', 'model.layers.15.self_attn.o_proj.bias', 'model.layers.25.mlp.down_proj.bias', 'model.layers.12.mlp.down_proj.bias', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.11.self_attn.o_proj.bias', 'model.layers.21.self_attn.o_proj.bias', 'model.layers.27.self_attn.o_proj.bias', 'model.layers.7.mlp.gate_proj.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.6.mlp.gate_proj.bias', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.8.mlp.up_proj.bias', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.18.self_attn.o_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.9.mlp.up_proj.bias', 'model.layers.2.self_attn.o_proj.bias', 'model.layers.6.mlp.down_proj.bias', 'model.layers.8.self_attn.o_proj.bias', 'model.layers.15.mlp.gate_proj.bias', 'model.layers.30.mlp.up_proj.bias'}\n- This IS expected if you are initializing MistralForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing MistralForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c1cfa6094f140b9a763179bf6fc0f39"}},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# Setting up the text generation process","metadata":{}},{"cell_type":"code","source":"generation_config = GenerationConfig(\n    do_sample=True,\n    top_k=1,\n    temperature=0.1,\n    max_new_tokens=100,\n    pad_token_id=tokenizer.eos_token_id\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:45:40.812677Z","iopub.execute_input":"2025-01-11T12:45:40.813016Z","iopub.status.idle":"2025-01-11T12:45:40.817384Z","shell.execute_reply.started":"2025-01-11T12:45:40.812990Z","shell.execute_reply":"2025-01-11T12:45:40.816440Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Inferences","metadata":{}},{"cell_type":"code","source":"# 1\n\ninputs = tokenizer(\"\"\"###Human: Sushi restaurants around me?  ###Assistant: \"\"\", return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(**inputs, generation_config=generation_config)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))\nprint()\nprint(f\"Inference Time: {time.time()-st_time}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:57:18.971847Z","iopub.execute_input":"2025-01-11T12:57:18.972210Z","iopub.status.idle":"2025-01-11T12:58:56.963124Z","shell.execute_reply.started":"2025-01-11T12:57:18.972179Z","shell.execute_reply":"2025-01-11T12:58:56.961785Z"}},"outputs":[{"name":"stdout","text":"###Human: Sushi restaurants around me?  ###Assistant: 1. Sushi Sensation\n2. Sushi Palace\n3. Sushi Delight\n4. Sushi Express\n5. Sushi Paradise\n6. Sushi Delight\n7. Sushi Delight\n8. Sushi Delight\n9. Sushi Delight\n10. Sushi Delight\n11. Sushi Delight\n12. Sushi Delight\n13\n\nInference Time: 470.38301181793213\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# 2\n\ninputs = tokenizer(\"\"\"###Human: Sushi restaurants around me and how to get to those places? ###Assistant: \"\"\", return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(**inputs, generation_config=generation_config)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))\nprint()\nprint(f\"Inference Time: {time.time()-st_time}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:58:56.964576Z","iopub.execute_input":"2025-01-11T12:58:56.964823Z","iopub.status.idle":"2025-01-11T13:00:34.948310Z","shell.execute_reply.started":"2025-01-11T12:58:56.964800Z","shell.execute_reply":"2025-01-11T13:00:34.947287Z"}},"outputs":[{"name":"stdout","text":"###Human: Sushi restaurants around me and how to get to those places? ###Assistant: 1. Sushi Sensation - 123 Main Street, Anytown, USA\n2. Sushi Palace - 456 Elm Street, Anytown, USA\n3. Sushi Delight - 789 Oak Street, Anytown, USA\n4. Sushi Paradise - 101 Pine Street, Anytown, USA\n5. Sushi Bliss - 222 Maple\n\nInference Time: 568.3676493167877\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# 3\n\ninputs = tokenizer(\"\"\"###Human: How to make the best noodles ever? ###Assistant: \"\"\", return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(**inputs, generation_config=generation_config)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))\nprint()\nprint(f\"Inference Time: {time.time()-st_time}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T13:00:34.949937Z","iopub.execute_input":"2025-01-11T13:00:34.950521Z","iopub.status.idle":"2025-01-11T13:02:12.928914Z","shell.execute_reply.started":"2025-01-11T13:00:34.950492Z","shell.execute_reply":"2025-01-11T13:02:12.928076Z"}},"outputs":[{"name":"stdout","text":"###Human: How to make the best noodles ever? ###Assistant: 1. Start by boiling water in a large pot.\n2. Add the noodles and cook according to the package instructions.\n3. Drain the noodles and set aside.\n4. In a separate pan, sauté some vegetables such as onions, garlic, and bell peppers.\n5. Add the cooked noodles to the pan and stir until the noodles are heated through.\n6. Add some sauce and stir until the\n\nInference Time: 666.3485112190247\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}